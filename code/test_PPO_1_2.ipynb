{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3911212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, torch, numpy as np, torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tianshou as ts\n",
    "from copy import deepcopy\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Independent, Normal\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from env import OilControlEnv\n",
    "from common.tools import load_json_config, load_sys_config\n",
    "from common.utils import *\n",
    "from common.log_path import make_logpath\n",
    "\n",
    "from solver.gurobi.solve import solve as gurobi_solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878dc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config_dir = \"./config\"\n",
    "env_configs = load_config(env_config_dir, 'oil_env')\n",
    "env_args = get_paras_from_dict(env_configs)\n",
    "env_all_conf = load_json_config(\"env/config.json\")\n",
    "env_conf = env_all_conf['Oil_Control']\n",
    "env_sys_conf = load_sys_config(env_args.config_path, env_args.model_id)\n",
    "env_run_dir, env_log_dir = make_logpath(env_args.scenario, env_args.algo)\n",
    "solver_reward_k = 0.002\n",
    "# 测试用环境\n",
    "# RL+求解器双层算法用\n",
    "class OilSupply_Env():\n",
    "    def __init__(self):\n",
    "        self.env = OilControlEnv(env_conf, env_sys_conf)\n",
    "        self.reset()\n",
    "        self.action_space = self.env.action_space\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_cnt = 0\n",
    "        self.state = self.env.reset()\n",
    "        obs = np.array(self.env.obs2vec(self.state))\n",
    "        self.obs_space = len(obs)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, vec_action):\n",
    "        self.step_cnt += 1\n",
    "        gurobi_action = self.RL_action2dict(vec_action)\n",
    "        dict_action, solver_obj = gurobi_solver(self.env.vertices, self.env.edges, gurobi_action, self.step_cnt, 0)\n",
    "        self.state, reward, done, info = self.env.step(dict_action)\n",
    "        info['action'] = gurobi_action\n",
    "        obs = np.array(self.env.obs2vec(self.state))\n",
    "        reward = reward*2 + 15.35\n",
    "#         reward -= solver_reward_k * solver_obj\n",
    "#         print(dict_action)\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def RL_action2dict(self, action):\n",
    "        action_dict = {}\n",
    "        action_dict = {}\n",
    "        idx = 0\n",
    "        vec = action.tolist()\n",
    "        for key in self.state.keys():\n",
    "            if key == \"transfer\":\n",
    "                action_dict['transfer'] = []\n",
    "                for item in self.state[key]:\n",
    "                    data = {}\n",
    "                    data['key'] = item['key']\n",
    "                    data['storage'] = dict(zip(item['materials'][1:], vec[idx:idx+len(item[\"storage\"])-1]))\n",
    "                    # data['storage'] = vec[idx:idx+len(item[\"storage\"])]\n",
    "                    idx += len(item['storage']) - 1\n",
    "                    action_dict['transfer'].append(data)\n",
    "            if key == \"refinery\":\n",
    "                action_dict['refinery'] = []\n",
    "                for item in self.state[key]:\n",
    "                    data = {}\n",
    "                    data['key'] = item['key']\n",
    "                    # if isinstance(item[\"left_JG_budget\"], list):\n",
    "                    #     data['left_JG_budget'] = vec[idx:idx+len(item[\"left_JG_budget\"])]\n",
    "                    #     idx += len(item[\"left_JG_budget\"])\n",
    "                    # if isinstance(item[\"left_JG_budget\"], int):\n",
    "                    #     data['left_JG_budget'] = {'JGHY': vec[idx]}\n",
    "                    #     idx += 1\n",
    "                    data['storage'] = {}\n",
    "                    for j in ['JGHY', \"PGLE\", \"PLDO\"]:\n",
    "                        if j in item[\"storage\"].keys():\n",
    "                            data['storage'][j] = vec[idx]\n",
    "                            idx += 1\n",
    "                    action_dict['refinery'].append(data)\n",
    "#         print(idx)\n",
    "        return action_dict\n",
    "\n",
    "# 纯RL算法用\n",
    "class OilSupply_Env1():\n",
    "    def __init__(self):\n",
    "        self.env = OilControlEnv(env_conf, env_sys_conf)\n",
    "        self.reset()\n",
    "        self.action_space = self.env.action_space\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_cnt = 0\n",
    "        self.state = self.env.reset()\n",
    "        obs = np.array(self.env.obs2vec(self.state))\n",
    "        self.obs_space = len(obs)\n",
    "        return obs\n",
    "    \n",
    "    def step(self, vec_action):\n",
    "        self.step_cnt += 1\n",
    "        action = self.env.vec2action(vec_action)\n",
    "        self.state, reward, done, info = self.env.step(action)\n",
    "        obs = np.array(self.env.obs2vec(self.state))\n",
    "        reward = reward*2 + 15.35\n",
    "#         print(dict_action)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "\n",
    "\n",
    "# sample_env = OilSupply_Env()\n",
    "# obs_space = sample_env.obs_space\n",
    "# action_space = sample_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b9dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_resblock_relu(nn.Module):\n",
    "    def __init__(self, in_ch, ch, out_ch=None, block_num=3, is_relu=True):\n",
    "        super().__init__()\n",
    "        self.models=nn.Sequential()\n",
    "        self.relus=nn.Sequential()\n",
    "        self.block_num = block_num\n",
    "        self.is_in = in_ch\n",
    "        self.is_out = out_ch\n",
    "        self.is_relu = is_relu\n",
    "        \n",
    "        if self.is_in:\n",
    "            self.in_mlp = nn.Sequential(*[\n",
    "                nn.Linear(in_ch, ch), \n",
    "                nn.LeakyReLU(0.1, inplace=True)])\n",
    "        for i in range(self.block_num):\n",
    "            self.models.add_module(str(i), nn.Sequential(*[\n",
    "                nn.Linear(ch, ch),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Linear(ch, ch)]))\n",
    "            self.relus.add_module(str(i), nn.Sequential(*[\n",
    "                nn.LeakyReLU(0.1, inplace=True)]))\n",
    "        if self.is_out:\n",
    "            self.out_mlp = nn.Sequential(*[\n",
    "            nn.Linear(ch, ch), \n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Linear(ch, out_ch)\n",
    "            ])\n",
    "        if self.is_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if self.is_in:\n",
    "            x = self.in_mlp(x)\n",
    "        for i in range(self.block_num):\n",
    "            x0 = x\n",
    "            x = self.models[i](x)\n",
    "            x += x0\n",
    "            x = self.relus[i](x)\n",
    "        if self.is_out:\n",
    "            x = self.out_mlp(x)\n",
    "        if self.is_relu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "MLP_CH = 1024\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, obs_space, action_space, is_gpu=True):\n",
    "        super().__init__()\n",
    "        self.is_gpu = is_gpu\n",
    "        self.net = mlp_resblock_relu(in_ch=obs_space, ch=MLP_CH, out_ch=action_space, block_num=6, is_relu=True)\n",
    "        self.sigma_param = nn.Parameter(torch.zeros(action_space, 1))\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        map_location=lambda storage, loc:storage\n",
    "        self.load_state_dict(torch.load(filename, map_location=map_location))\n",
    "        print('load model!')\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        print('save model!')\n",
    "\n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        obs = torch.tensor(obs).float()\n",
    "        if self.is_gpu:\n",
    "            obs = obs.cuda()\n",
    "        \n",
    "        mu = self.net(obs)\n",
    "        shape = [1] * len(mu.shape)\n",
    "        shape[1] = -1\n",
    "        sigma = (self.sigma_param.view(shape) + torch.zeros_like(mu)).exp()\n",
    "        return (mu,sigma), state\n",
    "\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, obs_space,is_gpu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_gpu = is_gpu\n",
    "        self.net = mlp_resblock_relu(in_ch=obs_space, ch=MLP_CH, out_ch=1, block_num=6, is_relu=False)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        map_location=lambda storage, loc:storage\n",
    "        self.load_state_dict(torch.load(filename, map_location=map_location))\n",
    "        print('load model!')\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "        print('save model!')\n",
    "\n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        obs = torch.tensor(obs).float()\n",
    "        if self.is_gpu:\n",
    "            obs = obs.cuda()\n",
    "        v = self.net(obs)\n",
    "\n",
    "        return v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4638c1fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"net.in_mlp.0.weight\", \"net.in_mlp.0.bias\", \"net.out_mlp.0.weight\", \"net.out_mlp.0.bias\", \"net.out_mlp.2.weight\", \"net.out_mlp.2.bias\". \n\tsize mismatch for sigma_param: copying a param with shape torch.Size([109, 1]) from checkpoint, the shape in current model is torch.Size([0, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\ZSY\\OilSupplyA_wjr10.19\\code\\test_PPO_1_2.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m,\u001b[39m20\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#     starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     load_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../model/ppo/ep\u001b[39m\u001b[39m%02d\u001b[39;00m\u001b[39m-actor.pth\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m(ep)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     actor\u001b[39m.\u001b[39;49mload_model(load_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     actor\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32md:\\study\\ZSY\\OilSupplyA_wjr10.19\\code\\test_PPO_1_2.ipynb Cell 4\u001b[0m in \u001b[0;36mActor.load_model\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     map_location\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m storage, loc:storage\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(filename, map_location\u001b[39m=\u001b[39;49mmap_location))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mload model!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\Zeyu\\miniconda3\\envs\\Venido\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"net.in_mlp.0.weight\", \"net.in_mlp.0.bias\", \"net.out_mlp.0.weight\", \"net.out_mlp.0.bias\", \"net.out_mlp.2.weight\", \"net.out_mlp.2.bias\". \n\tsize mismatch for sigma_param: copying a param with shape torch.Size([109, 1]) from checkpoint, the shape in current model is torch.Size([0, 1])."
     ]
    }
   ],
   "source": [
    "# 测RL+求解器双层方法\n",
    "env1 = OilSupply_Env()\n",
    "obs_space = env1.obs_space\n",
    "action_space = env1.action_space\n",
    "actor = Actor(is_gpu = False, obs_space=obs_space, action_space=action_space).cpu()\n",
    "# critic = Critic(is_gpu = is_gpu)\n",
    "\n",
    "load_path = None\n",
    "load_path = 'save/ppo/exp2/ep12-actor.pth'\n",
    "\n",
    "env1 = OilSupply_Env()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for ep in range(20,20+1):\n",
    "#     starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    load_path = '../model/ppo/ep%02d-actor.pth'%(ep)\n",
    "    actor.load_model(load_path)\n",
    "    actor.eval()\n",
    "    reward = 0\n",
    "    total_t = 0\n",
    "    warn_cnt = 0\n",
    "    obs = env1.reset()\n",
    "    t1 = time.clock()\n",
    "    for st in range(30):\n",
    "#         starter.record()\n",
    "        act,_ = actor([obs])\n",
    "        action = act[0].detach().view(-1).cpu().numpy()\n",
    "        # 服务器gpu常占用，需空闲时才能进行精确测时\n",
    "#         torch.cuda.synchronize()\n",
    "#         ender.record()\n",
    "#         curr_time = starter.elapsed_time(ender) # 计算时间\n",
    "#         tim1.append(curr_time)\n",
    "        \n",
    "#         starter.record()\n",
    "        action = (np.clip(action, -1.0, 1.0)+1)/2\n",
    "#         print(action)\n",
    "        obs, rew, done, info = env1.step(action)\n",
    "        torch.cuda.synchronize()\n",
    "#         ender.record()\n",
    "#         curr_time = starter.elapsed_time(ender) # 计算时间\n",
    "#         tim2.append(curr_time)\n",
    "        \n",
    "#         total_t += curr_time\n",
    "#         reward += rew*2+15.35\n",
    "        reward += rew\n",
    "        warn_cnt += info['split_rewards'][9]*100\n",
    "#         times.append(curr_time)\n",
    "#     times.append(total_t)\n",
    "# times = np.array(times)\n",
    "# tim1 = np.array(tim1)\n",
    "# tim2 = np.array(tim2)\n",
    "t2 = time.clock()\n",
    "print('episode:', ep, 'reward:', reward, 'warning:', int(-warn_cnt),'use time:', t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4fd26f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"net.in_mlp.0.weight\", \"net.in_mlp.0.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\ZSY\\OilSupplyA_wjr10.19\\code\\test_PPO_1_2.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     load_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../model/ppo2/ep\u001b[39m\u001b[39m%02d\u001b[39;00m\u001b[39m-actor.pth\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m(ep)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     actor\u001b[39m.\u001b[39;49mload_model(load_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     actor\u001b[39m.\u001b[39meval()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32md:\\study\\ZSY\\OilSupplyA_wjr10.19\\code\\test_PPO_1_2.ipynb Cell 5\u001b[0m in \u001b[0;36mActor.load_model\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     map_location\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m storage, loc:storage\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(filename, map_location\u001b[39m=\u001b[39;49mmap_location))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/ZSY/OilSupplyA_wjr10.19/code/test_PPO_1_2.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mload model!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\Zeyu\\miniconda3\\envs\\Venido\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Actor:\n\tUnexpected key(s) in state_dict: \"net.in_mlp.0.weight\", \"net.in_mlp.0.bias\". "
     ]
    }
   ],
   "source": [
    "# 测纯RL方法\n",
    "env2 = OilSupply_Env1()\n",
    "obs_space = env2.obs_space\n",
    "action_space = 87\n",
    "actor = Actor(is_gpu = True, obs_space=obs_space, action_space=action_space).cpu()\n",
    "# critic = Critic(is_gpu = is_gpu)\n",
    "\n",
    "# load_path = None\n",
    "# load_path = 'save/ppo2/exp2/ep00-actor.pth'\n",
    "# actor.load_model(load_path)\n",
    "# actor.eval()\n",
    "# print('ok')\n",
    "\n",
    "env2 = OilSupply_Env1()\n",
    "for ep in range(10,10+1):\n",
    "    load_path = '../model/ppo2/ep%02d-actor.pth'%(ep)\n",
    "    actor.load_model(load_path)\n",
    "    actor.eval()\n",
    "    reward = 0\n",
    "    total_t = 0\n",
    "    warn_cnt = 0\n",
    "    obs = env2.reset()\n",
    "    t1 = time.clock()\n",
    "    for st in range(30):\n",
    "        act,_ = actor([obs])\n",
    "        action = act[0].detach().view(-1).cpu().numpy()\n",
    "\n",
    "        action = (np.clip(action, -10.0, 10.0)+10)/2\n",
    "\n",
    "        obs, rew, done, info = env2.step(action)\n",
    "#         reward += rew*2+15.35\n",
    "        reward += rew\n",
    "        warn_cnt += info['split_rewards'][9]*100\n",
    "t2 = time.clock()\n",
    "print('episode:', ep, 'reward:', reward, 'warning:', int(-warn_cnt),'use time:', t2-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Venido')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a388516f6b692c0a62646c30410c343eb82ea693e95e0ed4c54f075e0ce13e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
